# Dropout

- 히든레이어의 일부 뉴런의 동작을 멈춰가며 모델을 학습시키는 전력이다.

# 사용하는 이유

- Overfitting 문제를 막기 위해서 사용한다.
- Regularization 효과를 줄 수 있다. (~ L1, L2 Regularization)
- 여러개의 모델을 학습하여 앙상블하는 효과를 줄 수 있다.

# 테스트 할때

- Dropout을 끄고 테스트를 진행한다.

